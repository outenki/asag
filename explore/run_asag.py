'''
Run training_testing progress for ASAG.
@outenki
@2018.4
'''
import os
import argparse

from multiprocessing import Pool
import matplotlib.pyplot as plt
plt.switch_backend('agg')

import utils_asag as U
import logging
import utils_svm as US

PARSER = argparse.ArgumentParser()
PARSER.add_argument('-k', '--kernel', dest='kernel', type=str, metavar='Kernel', required=False, default='linear', help="Kernel for SVR (linear|poly|rbf|sigmoid|precomputed), linear as default")
PARSER.add_argument('-p', '--penalty', dest='penalty', type=float, metavar='Penalty pamrameter', required=False, default=1.0, help="Penalty parameter C of error term, 1.0 as default")
PARSER.add_argument('-fp', '--feature_path', dest='feature_path', type=str, metavar="Path where TSV file of feature is", required=True, help="The patn name is appointed as param for gen_feature.py. The filename needs to be appointed by -fn") 
PARSER.add_argument('-fn', '--feature_name', dest='feature_name', type=str, metavar='Feature Name', required=True, help='name of feature stored in feature_path. (bow|)')
PARSER.add_argument('-vn', '--vocab_name', dest='vocab_name', type=str, metavar='Vocab File Name', required=False, default='vocab', help='name of vocab file. "vocab" as default')
PARSER.add_argument('-e', '--epsilon', dest='epsilon', type=float, metavar="Epsilon in the epsilon-SVR model", required=False, default=0.1, help="The feature file generated by gen_feature.py, 0.1 as default") 
PARSER.add_argument('-o', '--output', dest='path_out', type=str, metavar="Output Path", required=True, help="Path to output") 
PARSER.add_argument('-m', '--multiprocess', dest='multi_proc', type=int, metavar='Multi Processing', required=True, help='Number of multiprocessing')
PARSER.add_argument('-tr', '--train_ratio', dest='train_ratio', type=float, metavar='Train Ratio', required=False, default=0.8, help='Ratio of traing data. 0.8 as default, meaning 80% of data will be used as training data')
PARSER.add_argument('-nm', '--normalize', dest='normalize', type=bool, metavar='Normalize', required=False, default=True, help='Flat if clip the predicted labels. If TRUE is set, the predicted labels will be normalized to a range form true_label_min to true_label_max. Set as TRUE as default')
PARSER.add_argument('-ri', '--rint', dest='rint', type=bool, metavar='Rounded Int', required=False, default=True, help='The way to convert float pred to int labels. If TRUE is set, np.rint will be used instead of np.astype(int). True as default.')
PARSER.add_argument('-ts', '--training_scale', dest='training_scale', type=int, metavar='Training Scale ', required=False, default=0, help='Training scale. 0 as default, that all the training data will be used.')
PARSER.add_argument('-sc', '--SVC', dest='svc', type=bool, metavar='SVM Classify', required=False, default=False, help='If set as False (default), SVR will be applied. 2 ways SVC will be applied otherwise')
ARGS = PARSER.parse_args()

U.check_c_path(ARGS.path_out)
logging.basicConfig(
        filename='%s/svr.log' % ARGS.path_out,
        level=logging.INFO,
        format= '%(levelname)s:%(filename)s:%(asctime)s:%(message)s'
        )
LOGGER = logging.getLogger(__name__)

# FH = logging.FileHandler('%s/svr.log' % ARGS.path_out)
# FH.setLevel(logging.INFO)
# FH.setFormatter(formatter)
# SH = logging.StreamHandler()
# SH.setLevel(logging.INFO)
# SH.setFormatter(formatter)
# LOGGER.addHandler(FH)
# LOGGER.addHandler(SH)
# 

if __name__ == '__main__':
    U.print_args(ARGS)
    feature_path = ARGS.feature_path
    feature_name = ARGS.feature_name
    vocab_name = ARGS.vocab_name
    que_ids = sorted(list(os.listdir(feature_path)))
    size_que = len(que_ids)
    size_step = int(size_que / ARGS.multi_proc)

    pool = Pool()
    print(que_ids)
    for i in range(ARGS.multi_proc):
        que_list = que_ids[i::ARGS.multi_proc]
        # def run_svr(kernel, file_data, f_vocab, path_out, que_id, train_ratio=0.8, rint=True, training_scale=0, epsilon=0.1, penalty=1.0, normalize=False):
        # def run_svr_on_list(qids, feature_path, feature_name, vocab_name, kernel, path_out, train_ratio,
        #                       rint, training_scale, epsilon, penalty, normalize):
        pool.apply_async(US.run_svr_on_list, args=(que_list, feature_path, 
            feature_name, vocab_name, ARGS.kernel, ARGS.path_out, ARGS.train_ratio,
            ARGS.rint, ARGS.training_scale, ARGS.epsilon, ARGS.penalty, ARGS.normalize, ARGS.svc))
    pool.close()
    pool.join()
