from sklearn.svm import SVR
from multiprocessing import Pool

import os
import numpy as np
import argparse
import pickle
from utils import check_c_path, generate_training_test_data_f
import logging
from eva import RMSE, weightedF1, QWK
import operator

parser = argparse.ArgumentParser()
parser.add_argument('-k', '--kernel', dest='kernel', type=str, metavar='Kernel', required=False, default='linear', help="Kernel for SVR (linear|poly|rbf|sigmoid|precomputed), linear as default")
parser.add_argument('-p', '--penalty', dest='penalty', type=float, metavar='Penalty pamrameter', required=False, default=1.0, help="Penalty parameter C of error term, 1.0 as default")
parser.add_argument('-fp', '--feature_path', dest='feature_path', type=str, metavar="Path where TSV file of feature is", required=True, help="The patn name is appointed as param for gen_feature.py. The filename needs to be appointed by -fn") 
parser.add_argument('-fn', '--feature_name', dest='feature_name', type=str, metavar='Feature Name', required=True, help='name of feature stored in feature_path. (bow|)')
parser.add_argument('-vn', '--vocab_name', dest='vocab_name', type=str, metavar='Vocab File Name', required=False, default='vocab', help='name of vocab file. "vocab" as default')
parser.add_argument('-e', '--epsilon', dest='epsilon', type=float, metavar="Epsilon in the epsilon-SVR model", required=False, default=0.1, help="The feature file generated by gen_feature.py, 0.1 as default") 
# parser.add_argument('-v', '--vocab', dest='f_vocab', type=str, metavar="Vocabulary Pickle File", required=True, help="Path to vocab pickle file") 
parser.add_argument('-o', '--output', dest='path_out', type=str, metavar="Output Path", required=True, help="Path to output") 
parser.add_argument('-m', '--multiprocess', dest='multi_proc', type=int, metavar='Multi Processing', required=True, help='Number of multiprocessing')
parser.add_argument('-tr', '--train_ratio', dest='train_ratio', type=float, metavar='Train Ratio', required=False, default=0.8, help='Ratio of traing data. 0.8 as default, meaning 80% of data will be used as training data')
parser.add_argument('-nm', '--normalize', dest='normalize', type=bool, metavar='Normalize', required=True, help='Flat if clip the predicted labels. If TRUE is set, the predicted labels will be normalized to a range form true_label_min to true_label_max')
# parser.add_argument('-q', '--question', dest='que_id', type=str, metavar="Question ID", required=True, help="Question id, will be used to name output file") 
args = parser.parse_args()

check_c_path(args.path_out)
logging.basicConfig(
        filename='%s/svr.log' % args.path_out, 
        level=logging.INFO,
        format='%(levelname)s:%(asctime)s:%(message)s'
        )

logger = logging.getLogger(__name__)

def run_svr(kernel, file_data, f_vocab, path_out, que_id, train_ratio=0.8, epsilon=0.1, penalty=1.0, normalize=False):
    print("processing %s" % que_id)
    path_out = '%s/%s' % (path_out, que_id)
    check_c_path(path_out)

    logger.info('{}:Initialize SVR ...'.format(que_id))
    svr = SVR(C=penalty, epsilon=epsilon, kernel=kernel)
    logger.info('{}:Initialize training data and test data ...'.format(que_id))
    data_train, data_test = generate_training_test_data_f(file_data, train_ratio=train_ratio)

    # read vocab pickle file
    logger.info('{}:Reading vocab file ...'.format(que_id))
    with open(f_vocab, 'rb') as fv:
        vocab = pickle.load(fv)
    logger.info('{}:Reading vocab file ... DONE'.format(que_id))
    items = sorted(vocab.items(), key=operator.itemgetter(1))
    tokens = list(zip(*items))[0]
    logger.info('{}:Size of vocab : {}'.format(que_id, len(items)))
    with open('{}/tokens'.format(path_out), 'w') as ft:
        for t in tokens:
            ft.write('{}\n'.format(t))
    logger.info('{}:Tokens :{}'.format(que_id, tokens[:10]))

    # get features and scores from training data
    X = np.array(list(map(lambda r:r.split(','), data_train[:,3]))).astype(float)
    y = data_train[:,2]

    logger.info('{}:Training SVR ...'.format(que_id))
    svr.fit(X, y)

    # get features from test data
    logger.info('{}:Predicting test data ...'.format(que_id))
    X = np.array(list(map(lambda r:r.split(','), data_test[:,3]))).astype(float)
    y = svr.predict(X)
    score = data_test[:,2].astype(float)
    if normalize:
        v_max, v_min = max(score), min(score)
        y = y.clip(v_min, v_max)
    abs_diff = np.abs(y - score)
    results = np.column_stack((data_test[:,[0, 1, 2]], y.astype(str), abs_diff))

    # read weights of each n-gram token
    weight_token = svr.coef_
    logger.info('{}:Weights :{}'.format(que_id, weight_token.astype(str)))
    item_weight = list(zip(tokens, weight_token[0]))

    logger.info('{}:Output results ...'.format(que_id))
    f_pred = '%s/pred.txt' % path_out
    f_weight = '%s/weight.txt' % path_out
    f_eval = '%s/eval.txt' % path_out
    logger.info('{}:\tOutput pred to: {}'.format(que_id, f_pred))
    logger.info('{}:\tOutput weights to: {}'.format(que_id, f_weight))
    with open(f_pred, 'w') as fp, open(f_weight, 'w') as fw:
        # output results: AnswerID\tQuetionID\tScore\tPredict
        title = 'AnswerID\tQuetionID\tScore\tPredict\AbsDiff\n'
        fp.write(title)
        for l in results:
            fp.write('\t'.join(l)+'\n')
        logger.info('{}:\tOutput pred to: {} DONE!'.format(que_id, f_pred))

        # output weights of features: Token\tWeight
        title = 'Token\tWeight\n'
        fw.write(title)
        for i, w in item_weight:
            fw.write('{}\t{}\n'.format(i, w))
        logger.info('{}:\tOutput weights to: {} DONE!'.format(que_id, f_weight))


    # Evaluation with RMSE, QWK and wF1 score
    logger.info('{}:\tOutput evaluation to: {}'.format(que_id, f_eval))
    score_float = data_test[:,2].astype(float)
    pred_float = y
    score_int = score_float.astype(int)
    pred_int = y.astype(int)
    logger.info('{}:\tTrue labels: {}'.format(que_id, set(score_int)))
    logger.info('{}:\tPredicted labels: {}'.format(que_id, set(pred_int)))


    rmse = RMSE(score_float, pred_float)
    logger.info('{}:\trmse: {}'.format(que_id, rmse))
    qwk = QWK(score_int, pred_int)
    logger.info('{}:\tqwk: {}'.format(que_id, qwk))
    wf1 = weightedF1(score_int, pred_int)
    logger.info('{}:\twf1: {}'.format(que_id, wf1))
    logger.info('{}: QWK: {}, RMSE: {}, wF1: {}'.format(que_id, qwk, rmse, wf1))
    with open(f_eval, 'w') as fe:
        fe.write('RMSE: {}\n'.format(rmse))
        fe.write('QWK: {}\n'.format(qwk))
        fe.write('wF1: {}\n'.format(wf1))
    logger.info('{}: Done.'.format(que_id))

# run the script

def run_svr_on_list(qids):
    print(qids)
    for qid in qids:
        if not os.path.isdir('%s/%s' % (feature_path, qid)):
            logger.info('{}/{} is not dir. Skip it.'.format(feature_path, qid))
        file_data = '%s/%s/%s' % (feature_path, qid, feature_name)
        file_vocab = '%s/%s/%s' % (feature_path, qid, vocab_name)
        run_svr(args.kernel, file_data, file_vocab, args.path_out, qid, args.train_ratio, args.epsilon, args.penalty, args.normalize)
  
if __name__ == '__main__':
    feature_path = args.feature_path
    feature_name = args.feature_name
    vocab_name = args.vocab_name
    que_ids = sorted(list(os.listdir(feature_path)))
    size_que = len(que_ids)
    size_step = int(size_que / args.multi_proc)
    print('size_que:', size_que)
    print('multi_proc:', args.multi_proc)

    pool = Pool()
    print(que_ids)
    for i in range(args.multi_proc):
        que_list = que_ids[i::args.multi_proc]
        pool.apply_async(run_svr_on_list, args=(que_list, ))
    pool.close()
    pool.join()

