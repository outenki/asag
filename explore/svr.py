from sklearn.svm import SVR
import numpy as np
import argparse
import pickle
from utils import check_c_path, generate_training_test_data_f
import logging
from eval import RMSE, weightedF1, QWK

parser = argparse.ArgumentParser()
parser.add_argument('-k', '--kernel', dest='kernel', type=str, metavar='Kernel', required=False, default='linear', help="Kernel for SVR (linear|poly|rbf|sigmoid|precomputed), linear as default")
parser.add_argument('-p', '--penalty', dest='penalty', type=float, metavar='Penalty pamrameter', required=False, default=1.0, help="Penalty parameter C of error term, 1.0 as default")
parser.add_argument('-f', '--datafile', dest='file_data', type=str, metavar="Path to TSV file storing data", required=True, help="The feature file generated by gen_feature.py") 
parser.add_argument('-e', '--epsilon', dest='epsilon', type=float, metavar="Epsilon in the epsilon-SVR model", required=False, default=0.1, help="The feature file generated by gen_feature.py, 0.1 as default") 
parser.add_argument('-v', '--vocab', dest='f_vocab', type=str, metavar="Vocabulary Pickle File", required=True, help="Path to vocab pickle file") 
parser.add_argument('-o', '--output', dest='path_out', type=str, metavar="Output Path", required=True, help="Path to output") 
parser.add_argument('-q', '--question', dest='que_id', type=str, metavar="Question ID", required=True, help="Question id, will be used to name output file") 
args = parser.parse_args()

path_out = '%s/%s' % (args.path_out, args.que_id)
check_c_path(path_out)
logger = logging.getLogger(__name__)
logging.basicConfig(filename='%s/svr.log' % path_out, level=logging.INFO)

logger.info('Initialize SVR ...')
svr = SVR(C=args.penalty, epsilon=args.epsilon, kernel=args.kernel)
logger.info('Initialize training data and test data ...')
data_train, data_test = generate_training_test_data_f(args.file_data, train_ratio=0.8)

# get features and scores from training data
X = np.array(list(map(lambda r:r.split(','), data_train[:,3]))).astype(float)
y = data_train[:,2]

logger.info('Training SVR ...')
svr.fit(X, y)

# get features from test data
logger.info('Predicting test data ...')
X = np.array(list(map(lambda r:r.split(','), data_test[:,3]))).astype(float)
y = svr.predict(X)
results = np.column_stack((data_test[:,[0, 1, 2]], y.astype(str)))

# read weights of each n-gram token
weight_token = svr.coef_

# read vocab pickle file
logger.info('Reading vocab file ...')
with open(args.f_vocab, 'rb') as fv:
    vocab = pickle.load(fv)
items = sorted(vocab.items(), key=lambda i:(i[1], i[0]))
logger.info('Size of vocab : {}'.format(len(items)))
tokens = list(zip(*items))[0]
logger.info('Tokens :{}'.format(tokens[:10]))
logger.info('Weights :{}'.format(weight_token.astype(str)))
item_weight = list(zip(tokens, weight_token[0]))

logger.info('Output results ...')
f_pred = '%s/pred.txt' % path_out
f_weight = '%s/weight.txt' % path_out
logger.info('\tOutput pred to: %s' % f_pred)
logger.info('\tOutput weights to: %s' % f_weight)
with open(f_pred, 'w') as fp, open(f_weight, 'w') as fw:
    # output results: AnswerID\tQuetionID\tScore\tPredict
    title = 'AnswerID\tQuetionID\tScore\tPredict\n'
    fp.write(title)
    for l in results:
        fp.write('\t'.join(l)+'\n')

    # output weights of features: Token\tWeight
    title = 'Token\tWeight\n'
    fw.write(title)
    for i, w in item_weight:
        fw.write('{}\t{}\n'.format(i, w))

# Evaluation with RMSE, QWK and wF1 score
score_float = data_test[:2].astype(float)
pred_float = y
score_int = score_float.astype(int)
pred_int = y.astype(int)

rmse = RMSE(score_float, pred_float)
qwk = QWK(score_int, pred_int)
wf1 = weightedF1(score_int, pred_int)
logger.info('QWK: {}, RMSE: {}, wF1: {}'. format(qwk, rmse, wf1))

logger.info('Done.')
